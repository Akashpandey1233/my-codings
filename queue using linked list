#include <stdio.h>
#include <stdlib.h>
 
struct Node *f = NULL;
struct Node *r = NULL;
 
struct Node
{
    int data;
    struct Node *next;
};
 
void linkedListTraversal(struct Node *ptr)
{
    printf("Printing the elements of this linked list\n");
    while (ptr != NULL)
    {
        printf("Element: %d\n", ptr->data);
        ptr = ptr->next;
    }
}
 
void enqueue(int val)
{
    struct Node *n = (struct Node *) malloc(sizeof(struct Node));
    if(n==NULL){
        printf("Queue is Full");
    }
    else{
        n->data = val;
        n->next = NULL;
        if(f==NULL){
            f=r=n;
        }
        else{
            r->next = n;
            r=n;
        }
    }
}
 
int dequeue()
{
    int val = -1;
    struct Node *ptr = f;
    if(f==NULL){
        printf("Queue is Empty\n");
    }
    else{
        f = f->next;
        val = ptr->data;
        free(ptr);
    }
    return val;
}
 
int main()
{
    linkedListTraversal(f);
    printf("Dequeuing element %d\n", dequeue());
    enqueue(34);
    enqueue(4);
    enqueue(7);
    enqueue(17);
    printf("Dequeuing element %d\n", dequeue());
    printf("Dequeuing element %d\n", dequeue());
    printf("Dequeuing element %d\n", dequeue());
    printf("Dequeuing element %d\n", dequeue());
    linkedListTraversal(f);
    return 0;
}.

# python code to stream live video using opencv and jupyter
import cv2
video_capture = cv2.VideoCapture(0)
while True:
_, img = video_capture.read()
cv2.imshow("face detection", img)
if cv2.waitKey(1) & 0xFF == ord('q'):
break
video_capture.release()
cv2.destroyAllWindows()
#python code to detect a faces and area of interest from a live image
import cv2
def draw_boundary(img, classifier, scaleFactor, minNeigbors, color, text):
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
features = classifier.detectMultiScale(gray_img, scaleFactor, minNeigbors)
coords = []
for(x, y, w, h) in features:
cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)
cv2.putText(img, text, (x,y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)
coords = [x, y, w, h]
return coords, img
def detect(img, faceCascade):
color = {"blue":(255,0,0), "red":(0,0,255), "green":(0,255,0)}
coords, img = draw_boundary(img, faceCascade, 1.1, 10, color['blue'], "Face")
return img
faceCascade = cv2.CascadeClassifier("C:/Users/a/Desktop/major/codes/haarcascade_frontalface_default.xml")
video_capture = cv2.VideoCapture(0)
while True:
_, img = video_capture.read()
img = detect(img, faceCascade)
cv2.imshow("face detection", img)
if cv2.waitKey(1) & 0xFF == ord('q'):
break
video_capture.release()
cv2.destroyAllWindows()
#python program to detect eyes, nose, mouth, and face
import cv2
def draw_boundary(img, classifier, scaleFactor, minNeigbors, color, text):
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
features = classifier.detectMultiScale(gray_img, scaleFactor, minNeigbors)
coords = []
for(x, y, w, h) in features:
cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)
cv2.putText(img, text, (x,y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)
coords = [x, y, w, h]
return coords
def detect(img, faceCascade, eyesCascade, noseCascade, mouthCascade):
color = {"blue":(255,0,0), "red":(0,0,255), "green":(0,255,0), "white":(255,255,255)}
coords = draw_boundary(img, faceCascade, 1.1, 10, color['blue'], "Face")
if len(coords)==4:
roi_img = img[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]]
coords = draw_boundary(roi_img, eyesCascade, 1.1, 14, color['red'], "Eyes")
coords = draw_boundary(roi_img, noseCascade, 1.1, 4, color['green'], "Nose")
coords = draw_boundary(roi_img, mouthCascade, 1.1, 20, color['white'], "Mouth")
return img
[32]
faceCascade = cv2.CascadeClassifier("C:/Users/a/Desktop/major/codes/haarcascade_frontalface_default.xml")
eyesCascade = cv2.CascadeClassifier("C:/Users/a/Desktop/major/codes/haarcascade_eye.xml")
noseCascade = cv2.CascadeClassifier("C:/Users/a/Desktop/major/codes/haarcascade_mcs_nose.xml")
mouthCascade = cv2.CascadeClassifier("C:/Users/a/Desktop/major/codes/haarcascade_mcs_mouth.xml")
video_capture = cv2.VideoCapture(0)
while True:
_, img = video_capture.read()
img = detect(img, faceCascade, eyesCascade, noseCascade, mouthCascade)
cv2.imshow("face detection", img)
if cv2.waitKey(1) & 0xFF == ord('q'):
break
video_capture.release()
cv2.destroyAllWindows()
# face recognition -> creating datasets
import cv2
def generate_dataset(img, id, img_id):
cv2.imwrite("C:/Users/a/Desktop/major/codes/data/user."+str(id)+"."+str(img_id)+".jpg", img)
def draw_boundary(img, classifier, scaleFactor, minNeigbors, color, text):
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
features = classifier.detectMultiScale(gray_img, scaleFactor, minNeigbors)
coords = []
for(x, y, w, h) in features:
cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)
cv2.putText(img, text, (x,y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)
coords = [x, y, w, h]
return coords
def detect(img, faceCascade, eyesCascade, noseCascade, mouthCascade, img_id):
color = {"blue":(255,0,0), "red":(0,0,255), "green":(0,255,0), "white":(255,255,255)}
coords = draw_boundary(img, faceCascade, 1.1, 10, color['blue'], "Face")
if len(coords)==4:
roi_img = img[coords[1]:coords[1]+coords[3], coords[0]:coords[0]+coords[2]]
user_id = 1
generate_dataset(roi_img, user_id, img_id)
#coords = draw_boundary(roi_img, eyesCascade, 1.1, 14, color['red'], "Eyes")
#coords = draw_boundary(roi_img, noseCascade, 1.1, 4, color['green'], "Nose")
#coords = draw_boundary(roi_img, mouthCascade, 1.1, 20, color['white'], "Mouth")
return img
faceCascade = cv2.CascadeClassifier("C:/Users/a/Desktop/major/codes/haarcascade_frontalface_default.xml")
eyesCascade = cv2.CascadeClassifier("C:/Users/a/Desktop/major/codes/haarcascade_eye.xml")
noseCascade = cv2.CascadeClassifier("C:/Users/a/Desktop/major/codes/haarcascade_mcs_nose.xml")
mouthCascade = cv2.CascadeClassifier("C:/Users/a/Desktop/major/codes/haarcascade_mcs_mouth.xml")
video_capture = cv2.VideoCapture(0)
img_id = 0
while True:
_, img = video_capture.read()
img = detect(img, faceCascade, eyesCascade, noseCascade, mouthCascade, img_id)
cv2.imshow("face detection", img)
img_id += 1
if cv2.waitKey(1) & 0xFF == ord('q'):
break
video_capture.release()
cv2.destroyAllWindows()
# Training classifie
